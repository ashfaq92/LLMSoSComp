{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dd76b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: langchain-openai in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain-community in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langsmith in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (0.4.42)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-core) (2.11.9)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langsmith) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langsmith) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langsmith) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.1)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-openai) (2.7.2)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-community) (2.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\git_repos\\llmsoscomp\\.venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-core langchain-openai langchain-community langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5df6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass.getpass(\"Enter OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aba993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\") or getpass.getpass(\"Enter LangSmith API Key\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# you can change this as preferred\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG Demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eed6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b550934",
   "metadata": {},
   "source": [
    "# 1. `ConversationBufferMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3943e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "system_prompt = \"You are a helpful assistant called Gandalf.\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0155436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40e8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "chat_map = {}\n",
    "\n",
    "def get_chat_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_map[session_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d5a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e7e511d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, James! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 26, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-Cb6rEl2YwZCObvW10niEYIAVrKJTw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2d45889e-c5f2-4e2c-99d5-34f337c48519-0', usage_metadata={'input_tokens': 26, 'output_tokens': 11, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Hi, my name is James\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cbfc7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nimesi on James. Miten voin auttaa sinua tänään?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 52, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-Cb6rFAp2PsSQV18q1vBFwqYkj2UhK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--bf5d8e62-65de-4074-90e4-d180edfc9b70-0', usage_metadata={'input_tokens': 52, 'output_tokens': 16, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"mikä mun nimi oon?\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "500881d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I’m called Gandalf. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 81, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-Cb6rH7seKGEMBdEWLHKratIU7fR52', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--7ee0e04b-0a65-4279-bf27-c59074fd13fa-0', usage_metadata={'input_tokens': 81, 'output_tokens': 13, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"What is your name?\"},\n",
    "    config={\"session_id\": \"id_123\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b6c17",
   "metadata": {},
   "source": [
    "# 2. `ConversationBufferWindowMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e26ff4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class BufferWindowMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "    k: int = Field(default_factory=int)\n",
    "\n",
    "    def __init__(self, k: int):\n",
    "        super().__init__(k=k)\n",
    "        print(f\"Initializing BufferWindowMessageHistory with k={k}\")\n",
    "    \n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        self.messages.extend(messages)\n",
    "        self.messages = self.messages[-self.k:]  # keep only last k messages\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be63dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "\n",
    "def get_chat_history(session_id: str, k: int=4) -> BufferWindowMessageHistory:\n",
    "    print(f\"get chat history of last {k} messages for session {session_id}\")\n",
    "    if session_id not in chat_map:\n",
    "        chat_map[session_id] = BufferWindowMessageHistory(k=k)\n",
    "    # remove anything beyond the last\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bff4acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"The session ID to use for the chat history\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"k\",\n",
    "            annotation=int,\n",
    "            name=\"k\",\n",
    "            description=\"The number of messages to keep in the history\",\n",
    "            default=4\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b12d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get chat history of last 4 messages for session id_k4\n",
      "Initializing BufferWindowMessageHistory with k=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, Jamma! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 27, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb6rJTvrn7P9pOSpxYHmx4W89Lcuo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--4e0d73ab-d8ef-474a-9c95-f5a497517f34-0', usage_metadata={'input_tokens': 27, 'output_tokens': 12, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Hi, my name is Jamma\"},\n",
    "    config={\"configurable\": {\"session_id\": \"id_k4\", \"k\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43129b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map['id_k4'].clear()\n",
    "\n",
    "# manually insert history\n",
    "chat_map[\"id_k4\"].add_user_message(\"Hi, my name is James\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"I'm an AI model called Zeta.\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"I'm researching the different types of conversational memory.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"That's interesting, what are some examples?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"That's interesting, what's the difference?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"Buffer memory just stores the entire conversation, right?\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"That makes sense, what about ConversationBufferWindowMemory?\")\n",
    "chat_map[\"id_k4\"].add_user_message(\"Buffer window memory stores the last k messages, dropping the rest.\")\n",
    "chat_map[\"id_k4\"].add_ai_message(\"Very cool!\")\n",
    "\n",
    "chat_map[\"id_k4\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27b14a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get chat history of last 4 messages for session id_k14\n",
      "Initializing BufferWindowMessageHistory with k=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I don't know your name. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 25, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-Cb6uu8axQrQXryzsS8gxXuTHJr5mt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f59e4b2a-b009-4b7d-89c2-099c3d580373-0', usage_metadata={'input_tokens': 25, 'output_tokens': 17, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"what is my name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"id_k14\", \"k\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d7585",
   "metadata": {},
   "source": [
    "*Now let's initialize a new session with k=14*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04139784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get chat history of last 14 messages for session id_k14\n",
      "Initializing BufferWindowMessageHistory with k=14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, Jennifier! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 27, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb71dYBVws68HQ7RUhmVbFibdQVKQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--df168ef6-1f5c-4c7e-8c7b-4ac0e61658f8-0', usage_metadata={'input_tokens': 27, 'output_tokens': 12, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Hi, my name is Jennifier\"},\n",
    "    config={\"session_id\": \"id_k14\", \"k\": 14}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96798565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is Jennifier', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello, Jennifier! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 27, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb71dYBVws68HQ7RUhmVbFibdQVKQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--df168ef6-1f5c-4c7e-8c7b-4ac0e61658f8-0', usage_metadata={'input_tokens': 27, 'output_tokens': 12, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_k14\"].add_user_message(\"I'm researching the different types of conversational memory.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"That's interesting, what are some examples?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"That's interesting, what's the difference?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"Buffer memory just stores the entire conversation, right?\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"That makes sense, what about ConversationBufferWindowMemory?\")\n",
    "chat_map[\"id_k14\"].add_user_message(\"Buffer window memory stores the last k messages, dropping the rest.\")\n",
    "chat_map[\"id_k14\"].add_ai_message(\"Very cool!\")\n",
    "\n",
    "chat_map[\"id_k14\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d3c15e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get chat history of last 14 messages for session id_k14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Jennifier. How can I assist you further?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 159, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb72ErdxsjlwXzXQ6brPcYa963N4P', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e6a9ca6b-fe71-4a4a-8ab0-7ee6d12fea7c-0', usage_metadata={'input_tokens': 159, 'output_tokens': 13, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"what is my name again?\"},\n",
    "    config={\"session_id\": \"id_k14\", \"k\": 14}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42133d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is Jennifier', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello, Jennifier! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 27, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb71dYBVws68HQ7RUhmVbFibdQVKQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--df168ef6-1f5c-4c7e-8c7b-4ac0e61658f8-0', usage_metadata={'input_tokens': 27, 'output_tokens': 12, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is my name again?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Jennifier. How can I assist you further?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 159, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb72ErdxsjlwXzXQ6brPcYa963N4P', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e6a9ca6b-fe71-4a4a-8ab0-7ee6d12fea7c-0', usage_metadata={'input_tokens': 159, 'output_tokens': 13, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_k14\"].messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f095b",
   "metadata": {},
   "source": [
    "# 3. `ConversationSummaryMemory`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422fc0d",
   "metadata": {},
   "source": [
    "*impelmented with `RunnableWithMessageHistory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56a2dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "\n",
    "class ConversationSummaryMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "    llm: ChatOpenAI = Field(default_factory=ChatOpenAI)\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        super().__init__(llm=llm)\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add messages to the history, removing any messages beyond\n",
    "        the last `k` messages.\n",
    "        \"\"\"\n",
    "        self.messages.extend(messages)\n",
    "        # construct the summary chat messages\n",
    "        summary_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"Given the existing conversation summary and the new messages, \"\n",
    "                \"generate a new summary of the conversation. Ensuring to maintain \"\n",
    "                \"as much relevant information as possible.\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"Existing conversation summary:\\n{existing_summary}\\n\\n\"\n",
    "                \"New messages:\\n{messages}\"\n",
    "            )\n",
    "        ])\n",
    "        # format the messages and invoke the LLM\n",
    "        new_summary = self.llm.invoke(\n",
    "            summary_prompt.format_messages(\n",
    "                existing_summary=self.messages.content,\n",
    "                messages=[x.content for x in messages]\n",
    "            )\n",
    "        )\n",
    "        # replace the existing history with a single system summary message\n",
    "        self.messages = [SystemMessage(content=new_summary.content)]\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the history.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a40ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chat_map = {}\n",
    "def get_chat_history(session_id: str, llm: ChatOpenAI) -> ConversationSummaryMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exist, create a new chat history\n",
    "        chat_map[session_id] = ConversationSummaryMessageHistory(llm=llm)\n",
    "    # return the chat history\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "128809f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"The session ID to use for the chat history\",\n",
    "            default=\"id_default\",\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"llm\",\n",
    "            annotation=ChatOpenAI,\n",
    "            name=\"LLM\",\n",
    "            description=\"The LLM to use for the conversation summary\",\n",
    "            default=llm,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e3f142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: AttributeError(\"'list' object has no attribute 'content'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, James! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 26, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7HnnEkgVmBdFe8rS72VKRvldN94', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--3cce52a7-5702-45bd-85e5-6f4e4e4b7361-0', usage_metadata={'input_tokens': 26, 'output_tokens': 11, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Hi, my name is James\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": llm}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2a7d689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello, James! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 26, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7HnnEkgVmBdFe8rS72VKRvldN94', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--3cce52a7-5702-45bd-85e5-6f4e4e4b7361-0', usage_metadata={'input_tokens': 26, 'output_tokens': 11, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_123\"].messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83f92503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: AttributeError(\"'list' object has no attribute 'content'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello, James! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 26, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7HnnEkgVmBdFe8rS72VKRvldN94', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--3cce52a7-5702-45bd-85e5-6f4e4e4b7361-0', usage_metadata={'input_tokens': 26, 'output_tokens': 11, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That sounds like an interesting topic! Conversational memory can refer to various aspects of how conversations are remembered and processed. Here are a few types or concepts related to conversational memory:\\n\\n1. **Short-term Memory**: This involves the immediate recall of information exchanged during a conversation. It typically lasts for a few seconds to minutes and is crucial for maintaining the flow of dialogue.\\n\\n2. **Long-term Memory**: This refers to the retention of information from conversations over a longer period. It can include facts, experiences, and emotional responses associated with past interactions.\\n\\n3. **Working Memory**: This is a cognitive system that temporarily holds and manipulates information. In conversations, working memory allows individuals to keep track of what has been said and formulate responses.\\n\\n4. **Episodic Memory**: This type of memory involves recalling specific events or experiences, including the context of conversations. It helps individuals remember not just what was said, but also the circumstances surrounding the interaction.\\n\\n5. **Semantic Memory**: This refers to the storage of general knowledge and facts that can be recalled in conversations. It includes understanding language, concepts, and the meanings of words.\\n\\n6. **Social Memory**: This encompasses the collective memory of social interactions and relationships. It can influence how individuals remember conversations based on their social context and the people involved.\\n\\n7. **Contextual Memory**: This type of memory involves recalling the context in which a conversation took place, including the physical environment, emotional state, and social dynamics.\\n\\n8. **Narrative Memory**: This refers to the ability to remember and recount stories or narratives from conversations, which can help in understanding and sharing experiences.\\n\\nIf you have a specific aspect of conversational memory you’d like to explore further, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 355, 'prompt_tokens': 54, 'total_tokens': 409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7I6WL9F4XR1o0ZtpPQMYy1DvJoY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--4115cfe7-5287-4692-9dd5-aaafa95499c9-0', usage_metadata={'input_tokens': 54, 'output_tokens': 355, 'total_tokens': 409, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"I'm researching the different types of conversational memory.\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": llm}\n",
    ")\n",
    "\n",
    "chat_map[\"id_123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cba94123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: AttributeError(\"'list' object has no attribute 'content'\")\n",
      "Error in RootListenersTracer.on_chain_end callback: AttributeError(\"'list' object has no attribute 'content'\")\n",
      "Error in RootListenersTracer.on_chain_end callback: AttributeError(\"'list' object has no attribute 'content'\")\n"
     ]
    }
   ],
   "source": [
    "for msg in [\n",
    "    \"I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\",\n",
    "    \"Buffer memory just stores the entire conversation\",\n",
    "    \"Buffer window memory stores the last k messages, dropping the rest.\"\n",
    "]:\n",
    "    pipeline_with_history.invoke(\n",
    "        {\"query\": msg},\n",
    "        config={\"session_id\": \"id_123\", \"llm\": llm}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "113ff98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello, James! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 26, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7HnnEkgVmBdFe8rS72VKRvldN94', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--3cce52a7-5702-45bd-85e5-6f4e4e4b7361-0', usage_metadata={'input_tokens': 26, 'output_tokens': 11, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That sounds like an interesting topic! Conversational memory can refer to various aspects of how conversations are remembered and processed. Here are a few types or concepts related to conversational memory:\\n\\n1. **Short-term Memory**: This involves the immediate recall of information exchanged during a conversation. It typically lasts for a few seconds to minutes and is crucial for maintaining the flow of dialogue.\\n\\n2. **Long-term Memory**: This refers to the retention of information from conversations over a longer period. It can include facts, experiences, and emotional responses associated with past interactions.\\n\\n3. **Working Memory**: This is a cognitive system that temporarily holds and manipulates information. In conversations, working memory allows individuals to keep track of what has been said and formulate responses.\\n\\n4. **Episodic Memory**: This type of memory involves recalling specific events or experiences, including the context of conversations. It helps individuals remember not just what was said, but also the circumstances surrounding the interaction.\\n\\n5. **Semantic Memory**: This refers to the storage of general knowledge and facts that can be recalled in conversations. It includes understanding language, concepts, and the meanings of words.\\n\\n6. **Social Memory**: This encompasses the collective memory of social interactions and relationships. It can influence how individuals remember conversations based on their social context and the people involved.\\n\\n7. **Contextual Memory**: This type of memory involves recalling the context in which a conversation took place, including the physical environment, emotional state, and social dynamics.\\n\\n8. **Narrative Memory**: This refers to the ability to remember and recount stories or narratives from conversations, which can help in understanding and sharing experiences.\\n\\nIf you have a specific aspect of conversational memory you’d like to explore further, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 355, 'prompt_tokens': 54, 'total_tokens': 409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7I6WL9F4XR1o0ZtpPQMYy1DvJoY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--4115cfe7-5287-4692-9dd5-aaafa95499c9-0', usage_metadata={'input_tokens': 54, 'output_tokens': 355, 'total_tokens': 409, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='I have been looking at ConversationBufferMemory and ConversationBufferWindowMemory.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Great! Both **ConversationBufferMemory** and **ConversationBufferWindowMemory** are concepts often used in the context of conversational AI and natural language processing. They help manage and retain information during interactions. Here’s a brief overview of each:\\n\\n### ConversationBufferMemory\\n\\n- **Definition**: This type of memory stores the entire conversation history in a buffer. It allows the system to access previous messages and context as needed.\\n- **Use Case**: It is useful for applications where maintaining the full context of a conversation is important, such as in customer support or personal assistants. The system can refer back to earlier parts of the conversation to provide coherent and contextually relevant responses.\\n- **Limitations**: The main drawback is that it can become unwieldy if the conversation is very long, as it may require significant memory resources to store all previous exchanges.\\n\\n### ConversationBufferWindowMemory\\n\\n- **Definition**: This type of memory maintains a fixed-size window of the most recent messages in the conversation. Instead of storing the entire history, it only keeps a limited number of the latest exchanges.\\n- **Use Case**: This is beneficial in scenarios where only the most recent context is relevant for generating responses. It helps manage memory usage more efficiently while still allowing the system to maintain a sense of continuity in the conversation.\\n- **Limitations**: The downside is that it may lose important context from earlier parts of the conversation if they fall outside the fixed window, which could lead to less coherent responses in some cases.\\n\\n### Comparison\\n\\n- **Memory Management**: ConversationBufferMemory retains all conversation history, while ConversationBufferWindowMemory limits itself to a specific number of recent exchanges.\\n- **Contextual Relevance**: The former can provide richer context but at the cost of memory usage, while the latter is more efficient but may miss out on important earlier context.\\n- **Application Suitability**: The choice between the two often depends on the specific requirements of the application, such as the importance of historical context versus resource constraints.\\n\\nIf you have specific questions about how to implement or utilize these types of memory in a project, or if you want to explore their implications further, let me know!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 438, 'prompt_tokens': 431, 'total_tokens': 869, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7IY8dz7XzgvN2x1GPYWL2gR2Cm7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--08f9a65a-676a-4f93-af69-b36ad6880c24-0', usage_metadata={'input_tokens': 431, 'output_tokens': 438, 'total_tokens': 869, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='Buffer memory just stores the entire conversation', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Yes, that's correct! **ConversationBufferMemory** is designed to store the entire conversation history. This means that every message exchanged during the interaction is kept in memory, allowing the system to reference any part of the conversation at any time. \\n\\n### Key Features of ConversationBufferMemory:\\n\\n1. **Complete History**: It retains all messages, which can be beneficial for maintaining context and continuity throughout the conversation.\\n\\n2. **Contextual Awareness**: By having access to the entire conversation, the system can provide more relevant and coherent responses, as it can refer back to earlier statements or questions.\\n\\n3. **Use Cases**: This type of memory is particularly useful in applications where understanding the full context is crucial, such as:\\n   - Customer support chatbots that need to recall previous interactions.\\n   - Personal assistants that manage ongoing tasks or reminders.\\n   - Any conversational AI that requires a deep understanding of user intent over time.\\n\\n4. **Resource Intensive**: One of the main drawbacks is that it can consume a significant amount of memory, especially in long conversations. This can lead to performance issues if not managed properly.\\n\\n### Considerations\\n\\nWhen implementing **ConversationBufferMemory**, it's important to consider how long you want to retain the conversation history and how it might impact system performance. In some cases, you might want to implement strategies to manage memory usage, such as periodically clearing older messages or summarizing past interactions.\\n\\nIf you have more specific questions about how to implement or optimize this type of memory, or if you're looking for examples, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 312, 'prompt_tokens': 884, 'total_tokens': 1196, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7IiwneH0kz2IybxsOgMxK1oXZyh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d6c05f33-9b49-4b92-96f3-02cf4af2a4f1-0', usage_metadata={'input_tokens': 884, 'output_tokens': 312, 'total_tokens': 1196, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Yes, that's correct! **ConversationBufferWindowMemory** is designed to store only the most recent **k** messages in a conversation, effectively creating a sliding window of context. Here’s a more detailed breakdown:\\n\\n### Key Features of ConversationBufferWindowMemory:\\n\\n1. **Fixed Size**: It maintains a limited number of messages (the last **k** messages), which means that as new messages come in, older messages are dropped from memory. This helps manage memory usage effectively.\\n\\n2. **Recent Context**: By focusing on the most recent exchanges, this type of memory allows the system to respond based on the latest context, which is often sufficient for many conversational applications.\\n\\n3. **Efficiency**: Since it only retains a small portion of the conversation, it is less resource-intensive compared to storing the entire conversation history. This can lead to faster processing times and lower memory consumption.\\n\\n4. **Use Cases**: This approach is particularly useful in scenarios where:\\n   - The most recent context is more relevant than older exchanges (e.g., ongoing chats where the topic hasn't changed).\\n   - Memory resources are limited, and maintaining a full history is impractical.\\n   - Applications that require quick responses without needing to reference long past interactions.\\n\\n### Considerations\\n\\nWhile **ConversationBufferWindowMemory** is efficient, it does have some limitations:\\n\\n- **Loss of Context**: Important information from earlier in the conversation may be lost if it falls outside the fixed window. This can lead to less coherent responses if the conversation requires referencing earlier context.\\n  \\n- **Window Size**: Choosing the right size for **k** is crucial. If it's too small, the system may not have enough context to respond appropriately. If it's too large, it may negate some of the memory efficiency benefits.\\n\\nIn summary, **ConversationBufferWindowMemory** is a practical approach for managing conversational context while balancing memory usage and performance. If you have further questions or need examples of how to implement this type of memory, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 403, 'prompt_tokens': 1217, 'total_tokens': 1620, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7Io54yypBkESWs5YwTp77f8dPTR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8fb6e51d-124f-40d4-83b9-900075917b70-0', usage_metadata={'input_tokens': 1217, 'output_tokens': 403, 'total_tokens': 1620, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_map[\"id_123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ed4b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: AttributeError(\"'list' object has no attribute 'content'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is James! How can I assist you further today, James?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 1634, 'total_tokens': 1649, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1536}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-Cb7KBO7coAwxYj0dFFbD5egqnx9r2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--67e1fbac-e0c1-42c2-a920-39b697be14d3-0', usage_metadata={'input_tokens': 1634, 'output_tokens': 15, 'total_tokens': 1649, 'input_token_details': {'audio': 0, 'cache_read': 1536}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"What is my name again?\"},\n",
    "    config={\"session_id\": \"id_123\", \"llm\": llm}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60740e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
